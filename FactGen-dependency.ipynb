{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzIby1P5l1PxWv7wUhEpr9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadz-khan/tukl-intern-prog/blob/master/FactGen-dependency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__uVx1j_kaFo",
        "outputId": "2dbe8a69-fe79-42e4-8261-0a54f4529131"
      },
      "source": [
        "!git clone https://github.com/harvardnlp/encoder-agnostic-adaptation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'encoder-agnostic-adaptation'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Total 175 (delta 0), reused 0 (delta 0), pack-reused 175\u001b[K\n",
            "Receiving objects: 100% (175/175), 448.17 KiB | 2.17 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmqdwo6zlbP9",
        "outputId": "ea0ec28e-ddc6-443c-8e27-39f750d49174"
      },
      "source": [
        "%cd /content/encoder-agnostic-adaptation/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/encoder-agnostic-adaptation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO26-PgZk5yW",
        "outputId": "991b1854-e26c-4dd1-f3fb-abf54533b809"
      },
      "source": [
        "!mkdir /content/encoder-agnostic-adaptation/data\n",
        "%cd /content/encoder-agnostic-adaptation/data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/encoder-agnostic-adaptation/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pMopHvakkU3",
        "outputId": "fd3e7ad4-1a65-4a5f-f3a4-bd502680befa"
      },
      "source": [
        "!tar -xvf /content/drive/MyDrive/NLP\\ Datasets/Cleaned/data.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "content/FactGen/code/FactGen/data/cnndm/\n",
            "content/FactGen/code/FactGen/data/cnndm/train.txt.src\n",
            "content/FactGen/code/FactGen/data/cnndm/train.txt.src.bpe\n",
            "content/FactGen/code/FactGen/data/cnndm/.ipynb_checkpoints/\n",
            "content/FactGen/code/FactGen/data/cnndm/val.txt.src\n",
            "content/FactGen/code/FactGen/data/cnndm/val.txt.src.bpe\n",
            "content/FactGen/code/FactGen/data/cnndm/test.txt.src.bpe\n",
            "content/FactGen/code/FactGen/data/cnndm/test.txt.tgt.bpe\n",
            "content/FactGen/code/FactGen/data/cnndm/val.txt.tgt.bpe\n",
            "content/FactGen/code/FactGen/data/cnndm/test.txt.src\n",
            "content/FactGen/code/FactGen/data/cnndm/train.txt.tgt.bpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnfkZlMZ_ISG"
      },
      "source": [
        "!rm -rf /content/encoder-agnostic-adaptation/data/content"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boZwWvLFlArG",
        "outputId": "a7442365-293e-4362-b256-58391bc7e995"
      },
      "source": [
        "%cd /content/encoder-agnostic-adaptation/gpt2 \n",
        "!python download_model.py 124M"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/encoder-agnostic-adaptation/gpt2\n",
            "Fetching checkpoint: 1.00kit [00:00, 579kit/s]                                                      \n",
            "Fetching encoder.json: 1.00kit [00:00, 851kit/s]                                                    \n",
            "Fetching hparams.json: 1.00kit [00:00, 828kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.00kit [00:00, 551kit/s]                                  \n",
            "Fetching model.ckpt.index: 1.00kit [00:00, 889kit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.00kit [00:00, 890kit/s]                                                 \n",
            "Fetching vocab.bpe: 1.00kit [00:00, 903kit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh_-spjNy1ok",
        "outputId": "a2e030ed-5dee-4212-8215-03ac80fc887d"
      },
      "source": [
        "!pip install iopath"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting iopath\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from iopath) (4.30.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.1-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker, iopath\n",
            "Successfully installed iopath-0.1.9 portalocker-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I83wKdUhE4J0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i8NANa7SBHMV",
        "outputId": "b8b28b6c-128a-4415-e020-11a2729c49a0"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.1'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j52gUxmVGMRM",
        "outputId": "f1421942-8bb5-418e-ab93-e9bd5921418f"
      },
      "source": [
        "!pip uninstall torch\n",
        "!pip uninstall torchtext\n",
        "!pip uninstall torchvision\n",
        "!pip install torch==1.4.* torchtext==0.5\n",
        "!pip install torchvision==0.4.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.9.0+cu102\n",
            "Uninstalling torch-1.9.0+cu102:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.7/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch-1.9.0+cu102.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.9.0+cu102\n",
            "Found existing installation: torchtext 0.10.0\n",
            "Uninstalling torchtext-0.10.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/torchtext-0.10.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torchtext/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchtext-0.10.0\n",
            "Found existing installation: torchvision 0.10.0+cu102\n",
            "Uninstalling torchvision-0.10.0+cu102:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision-0.10.0+cu102.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libcudart.459720b2.so.10.2\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libnvjpeg.a6b52b54.so.10\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libz.1328edc3.so.1\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Collecting torch==1.4.*\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.6 kB/s \n",
            "\u001b[?25hCollecting torchtext==0.5\n",
            "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5) (4.62.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5) (3.0.4)\n",
            "Installing collected packages: torch, sentencepiece, torchtext\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Successfully installed sentencepiece-0.1.96 torch-1.4.0 torchtext-0.5.0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torchvision==0.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 19.9 MB/s \n",
            "\u001b[?25hCollecting torch==1.2.0\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1 MB 1.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wzeGZ3PA1yV"
      },
      "source": [
        "mem = []\n",
        "while True:\n",
        "    mem.append(' ' * 10**6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aGME0P3msCn",
        "outputId": "3ecfcc32-157f-48bd-e728-efc6c7d9791f"
      },
      "source": [
        "%cd /content/encoder-agnostic-adaptation/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/encoder-agnostic-adaptation/'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGj4JTnbu4bf",
        "outputId": "31a7ace5-898a-437a-a8ed-25829c004d48"
      },
      "source": [
        "!pip install configargparse"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.2-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: configargparse\n",
            "Successfully installed configargparse-1.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FfYBBfvq6_D",
        "outputId": "ae19b39d-ec54-4b71-b0bd-8bc3e575393e"
      },
      "source": [
        "!python encode_text.py --directory /content/encoder-agnostic-adaptation/data/cnndm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"encode_text.py\", line 2, in <module>\n",
            "    from pytorch_pretrained_bert import GPT2Tokenizer\n",
            "ModuleNotFoundError: No module named 'pytorch_pretrained_bert'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7TnOAwglDxq",
        "outputId": "eac0dbd0-5b30-45e8-cdc8-a30b43440f6f"
      },
      "source": [
        "!python preprocess.py -train_src /content/encoder-agnostic-adaptation/data/cnndm/train.txt.src.bpe -train_tgt /content/encoder-agnostic-adaptation/data/cnndm/train.txt.tgt.bpe -valid_src /content/encoder-agnostic-adaptation/data/cnndm/val.txt.src.bpe -valid_tgt /content/encoder-agnostic-adaptation/data/cnndm/val.txt.tgt.bpe -save_data data/cnndm/CNN_BPETGT -tgt_seq_length_trunc 400 -tgt_vocab gpt2/vocab.txt -fixed_vocab -free_src"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-08-23 17:14:07,296 INFO] Extracting features...\n",
            "[2021-08-23 17:14:07,301 INFO]  * number of source features: 0.\n",
            "[2021-08-23 17:14:07,301 INFO]  * number of target features: 0.\n",
            "[2021-08-23 17:14:07,302 INFO] Building `Fields` object...\n",
            "[2021-08-23 17:14:07,302 INFO] Building & saving training data...\n",
            "[2021-08-23 17:14:07,302 INFO] Reading source and target files: /content/encoder-agnostic-adaptation/data/cnndm/train.txt.src.bpe /content/encoder-agnostic-adaptation/data/cnndm/train.txt.tgt.bpe.\n",
            "[2021-08-23 17:14:24,160 INFO] Building shard 0.\n",
            "[2021-08-23 17:14:58,026 INFO]  * saving 0th train data shard to data/cnndm/CNN_BPETGT.train.0.pt.\n",
            "tcmalloc: large alloc 1073741824 bytes == 0x563b87f5e000 @  0x7fb1849c31e7 0x563ab3998488 0x563ab3a1adef 0x563ab3a17a2e 0x563ab3a17f17 0x563ab3a18782 0x563ab3a188d1 0x563ab3a195dc 0x563ab3a1820a 0x563ab3a17f61 0x563ab3a18968 0x563ab3a195dc 0x563ab3a1820a 0x563ab3a1716c 0x563ab3aada2b 0x563ab3965e4d 0x563ab3a57c0d 0x563ab39da0d8 0x563ab39d5235 0x563ab396773a 0x563ab39d5b0e 0x563ab39d5235 0x563ab396773a 0x563ab39d5b0e 0x563ab396765a 0x563ab39d5b0e 0x563ab39d5235 0x563ab396773a 0x563ab39d9f40 0x563ab39d4c35 0x563ab396773a\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp-kz5vOrWDF",
        "outputId": "dde0f09c-20cc-4594-8500-53f18ad929c2"
      },
      "source": [
        "!python train.py -config /content/encoder-agnostic-adaptation/config/cnndm/transformer_cnndm_baseline.yml -run_name psa -gpt2_params_path gpt2/models/124M/ -gpt2_init_embanddec"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote config file to output/cnndm_CNNDM_BPE_COPY/transformer_cnndm_baseline_psa/config.yml\n",
            "THCudaCheck FAIL file=/pytorch/torch/csrc/cuda/Module.cpp line=37 error=10 : invalid device ordinal\n",
            "THCudaCheck FAIL file=/pytorch/torch/csrc/cuda/Module.cpp line=37 error=10 : invalid device ordinal\n",
            "THCudaCheck FAIL file=/pytorch/torch/csrc/cuda/Module.cpp line=37 error=10 : invalid device ordinal\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 144, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 38, in main\n",
            "    p.join()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
            "Error in atexit._run_exitfuncs:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/__init__.py\", line 38, in _set_python_exit_flag\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
            "Process SpawnProcess-4:\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "  File \"train.py\", line 95, in signal_handler\n",
            "    raise Exception(msg)\n",
            "Exception: \n",
            "\n",
            "-- Tracebacks above this line can probably\n",
            "                 be ignored --\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/encoder-agnostic-adaptation/train.py\", line 53, in run\n",
            "    single_main(opt, device_id)\n",
            "  File \"/content/encoder-agnostic-adaptation/onmt/train_single.py\", line 71, in main\n",
            "    vocab = torch.load(opt.data + '.vocab.pt')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 381, in load\n",
            "    f = open(f, 'rb')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'data/cnndm/CNNDM_BPE_COPY.vocab.pt'\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/encoder-agnostic-adaptation/train.py\", line 53, in run\n",
            "    single_main(opt, device_id)\n",
            "  File \"/content/encoder-agnostic-adaptation/onmt/train_single.py\", line 50, in main\n",
            "    configure_process(opt, device_id)\n",
            "  File \"/content/encoder-agnostic-adaptation/onmt/train_single.py\", line 43, in configure_process\n",
            "    torch.cuda.set_device(device_id)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\", line 281, in set_device\n",
            "    torch._C._cuda_setDevice(device)\n",
            "RuntimeError: cuda runtime error (10) : invalid device ordinal at /pytorch/torch/csrc/cuda/Module.cpp:37\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/encoder-agnostic-adaptation/train.py\", line 53, in run\n",
            "    single_main(opt, device_id)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAqFlZQRmuZg"
      },
      "source": [
        "from torch.utils import data"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}